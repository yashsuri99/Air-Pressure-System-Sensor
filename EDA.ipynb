{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statistics import mean\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "import miceforest as mf\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'https://raw.githubusercontent.com/avnyadav/sensor-fault-detection/main/aps_failure_training_set1.csv', na_values=\"na\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "print('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\n",
    "\n",
    "print('We have {} categorical features : {}'.format(len(categorical_features),categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot missing values count for each column\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "missing = df.isna().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0, ascending=False)\n",
    "\n",
    "ax.bar(missing.index, missing.values.T[0])\n",
    "plt.xticks([])\n",
    "plt.ylabel(\"Percentage Missing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns which has more than 70% missing values\n",
    "\n",
    "dropCols = missing[missing[0] > 70]\n",
    "dropCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(dropCols.index), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "print(\"Percentage of total missing cells in the data {}%\".format((total_missing/total_cells)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = df[df['class'] == 'pos'].shape[0]\n",
    "neg = df[df['class'] == 'neg'].shape[0]\n",
    "print(\"Postitve: \" + str(pos) + \", Negative: \" + str(neg))\n",
    "sns.catplot(data = df, x = \"class\", kind=\"count\", alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will use smote technique to handle oversampling of data that can be seen here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_scores(true,predicted):\n",
    "  \n",
    "  acc = accuracy_score(true,predicted)\n",
    "  f1 = f1_score(true,predicted)\n",
    "  precision = precision_score(true,predicted)\n",
    "  recall = recall_score(true,predicted)\n",
    "  roc_auc = roc_auc_score(true,predicted)\n",
    "  \n",
    "  return acc,f1,precision,recall,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(y_true, y_pred):\n",
    "  \n",
    "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "  cost = 10*fp + 500*fn\n",
    "  return cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X,y,models):\n",
    "  \n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "  cost_list=[]\n",
    "  models_list = []    \n",
    "  accuracy_list = []\n",
    "    \n",
    "  for i in range(len(list(models))):\n",
    "      model = list(models.values())[i]\n",
    "      model.fit(X_train, y_train)\n",
    "        \n",
    "      y_train_pred = model.predict(X_train)\n",
    "      y_test_pred = model.predict(X_test)\n",
    "        \n",
    "      model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "      model_train_recall,model_train_rocauc_score=evaluate_scores(y_train ,y_train_pred)\n",
    "      train_cost = total_cost(y_train, y_train_pred)\n",
    "\n",
    "      model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "      model_test_recall,model_test_rocauc_score=evaluate_scores(y_test, y_test_pred)\n",
    "      test_cost = total_cost(y_test, y_test_pred)\n",
    "\n",
    "      print(list(models.keys())[i])\n",
    "      models_list.append(list(models.keys())[i])\n",
    "\n",
    "      print('Model performance for Training set')\n",
    "      print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "      print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "      print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "      print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "      print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "      print(f'- COST: {train_cost}.')\n",
    "\n",
    "      print('Model performance for Test set')\n",
    "      print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "      print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "      print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "      print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "      print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "      print(f'- COST: {test_cost}.')\n",
    "      cost_list.append(test_cost)\n",
    "      print('='*35)\n",
    "        \n",
    "  report=pd.DataFrame(list(zip(models_list, cost_list)), columns=['Model Name', 'Cost']).sort_values(by=[\"Cost\"])\n",
    "        \n",
    "  return report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will plot 170 graphs as the number of numeric features and will provide us the distribution of values in each column\n",
    "## Run at your own risk takes atleast 5 mins\n",
    "## distplot in this is deprecated change to displot \n",
    "\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "\n",
    "# plt.figure(figsize=(15,100))\n",
    "# for i , col in enumerate(numeric_features):\n",
    "#   plt.subplot(60,3,i+1)\n",
    "#   sns.distplot(x=df[col], color = 'indianred')\n",
    "#   plt.xlabel(col, weight='bold')\n",
    "#   plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({'pos': 1, 'neg': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratergy 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with robust scaler for KNN K-Selection\n",
    "\n",
    "robust_scaler = RobustScaler()\n",
    "X1 = robust_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tries to fix the the empty values on the basis of neighbouring value\n",
    "This code will take alot of time but is necessary for fixing the values\n",
    "Run only once as will take hours to run this even on a good machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "\n",
    "# imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "# strategies = [str(i) for i in [1,3,5,7]]\n",
    "# for s in strategies:\n",
    "#   pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(s))), ('m', LogisticRegression())])\n",
    "#   scores = cross_val_score(pipeline, X1, y, scoring='accuracy', cv=2, n_jobs=1)\n",
    "#   results.append(scores)\n",
    "#   print(\"n_neighbours: {} || accuracy_score: {:.4f}\".format(int(s), mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have maximum accuracy when number of neighbours is 3 \n",
    "\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "  ('imputer', KNNImputer(n_neighbors=3)),\n",
    "  ('robustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_knn = knn_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Will use Smote Tomek to remove overlapping data points also will create synthetic data for minority class and remove excess data from majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling minority class.\n",
    "\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority', n_jobs=1)\n",
    "\n",
    "X_res, y_res = smt.fit_resample(X_knn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of default models that can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_knn = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratergy 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "num_features\n",
    "\n",
    "median_pipeline = Pipeline(steps=[\n",
    "  ('imputer', SimpleImputer(strategy='median')),\n",
    "  ('robustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_median = median_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTETomek(random_state=42, sampling_strategy='minority')\n",
    "\n",
    "X_res, y_res = smt.fit_resample(X_median, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_median = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratergy 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mice = X.copy()\n",
    "kernel = mf.ImputationKernel(\n",
    "  X_mice,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1999\n",
    ")\n",
    "kernel.mice(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mice = kernel.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_pipeline = Pipeline(steps=[\n",
    "  ('robustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mice = mice_pipeline.fit_transform(X_mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTETomek(random_state=42, sampling_strategy='minority', n_jobs=-1)\n",
    "\n",
    "X_res, y_res = smt.fit_resample(X_mice,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_mice = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_mice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratergy 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_pipeline = Pipeline(steps=[\n",
    "    ('Imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_const =constant_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority', n_jobs=-1 )\n",
    "\n",
    "X_res, y_res = smt.fit_resample(X_const, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_const = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratergy 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pipeline = Pipeline(steps=[\n",
    "    ('Imputer', SimpleImputer(strategy='mean')),\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = mean_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority' , n_jobs=-1)\n",
    "\n",
    "X_res, y_res = smt.fit_resample(X_mean, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_mean = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
